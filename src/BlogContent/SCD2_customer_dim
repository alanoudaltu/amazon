-- create the customer dimension table with added hash column and timestamp tracking
DROP TABLE IF EXISTS customer_dim CASCADE;
CREATE TABLE customer_dim ( 
customer_dim_id     bigint GENERATED BY DEFAULT AS IDENTITY(1, 1), 
c_custkey           bigint distkey, 
c_name              CHARACTER VARYING(30), 
c_address            CHARACTER VARYING(50), 
c_nationkey         integer, 
c_phone             CHARACTER VARYING(20), 
c_acctbal           NUMERIC(12, 2), 
c_mktsegment        CHARACTER VARYING(10), 
c_comment           CHARACTER VARYING(120), 
track_hash          bigint, 
record_start_ts     timestamp WITHOUT time ZONE 
                    DEFAULT '1970-01-01 00:00:00'::timestamp WITHOUT time ZONE, 
record_end_ts       timestamp WITHOUT time ZONE 
                    DEFAULT '2999-12-31 00:00:00'::timestamp WITHOUT time ZONE, 
record_active_flag  SMALLINT DEFAULT 1, 
record_upd_ts       timestamp WITHOUT time ZONE DEFAULT NULL, 
record_insert_ts    timestamp WITHOUT time ZONE DEFAULT current_timestamp 
)
DISTSTYLE KEY 
SORTKEY (c_custkey);

-- populate dimension and hash based off of (address and phone) as drivers
insert into customer_dim 
    (c_custkey, c_name, c_address, c_nationkey, c_phone,
     c_acctbal, c_mktsegment, c_comment, track_hash) 
select
    c.c_custkey, c.c_name, 
    cast(c.c_address as varchar(50)) as c_address,
    c.c_nationkey, cast(c.c_phone as varchar(20)) as c_phone, 
    c.c_acctbal, c.c_mktsegment, c.c_comment, 
    FNV_HASH(c_address+c_phone) as track_hash
from
    customer c
;

-- check customers count and look at sample data
select count(1) from customer_dim; 
select * from customer_dim limit 10;

By setting end timestamp to high date like 31 December 2999 as used here, and record active flag as 1 we have marked all current records as active rows in the customer dimension. 
As the data changes come in to the DWH we shall “close out” the open customer record by setting the end timestamp value and record active flag. And create a new version of customer record with current timestamp for start timestamp, use high date for end timestamp and 1 for record active flag.

Let’s create a dummy source data table from OLTP system. Here we simulate 
•	Change to Phone for 200 customers – type 2
•	Change to Address for 500 customers – type 2
•	Change to Name for 150 customers – type 1
•	Completely new customers added to OLTP

-- create a source table from OLPT system dummy data
-- where phone has changed for 200 customers
drop table if exists src_customer;
create table src_customer distkey(custkey) as 
select
    c_custkey as custkey, c_name as name, c_address as address, 
    c_nationkey as nationkey, c_phone+'0' as phone, c_acctbal as acctbal, 
    c_mktsegment as mktsegment, cast('Update 1' as varchar(120)) as comment,
    getdate() as effective_dt
from 
    customer_dim
limit 200
;

-- address has changed for 500 customers
insert into src_customer
select
    c_custkey as custkey, c_name as name, 
    c_address+'Z' as address, c_nationkey as nationkey, 
    c_phone as phone, c_acctbal as acctbal, 
    c_mktsegment as mktsegment, 'Update 2' as comment,
    getdate() as effective_dt
from
    customer_dim
where
    c_custkey not in (select custkey from src_customer)
limit 500
;

-- name has changed for 150 customers
insert into src_customer
select
    c_custkey as custkey, c_name+'.' as name, 
    c_address as address, c_nationkey as nationkey, 
    c_phone as phone, c_acctbal as acctbal, 
    c_mktsegment as mktsegment, 'Update 3' as comment,
    getdate() as effective_dt
from
    customer_dim
where
    c_custkey not in (select custkey from src_customer)
limit 150
;

-- also let's add three completely new customers
insert into src_customer values
(15000001, 'Customer#15000001', '1 Main Street, Somewhere, Zip 10001', 
 7, '56-451-856-9532', 8612.30 , 'BUILDING' , 'NC#1', getdate()            ),
(15000002, 'Customer#15000002', '2 First Street, Herethere, Zip 50006', 
 15, '65-125-586-3249', 65112.30 , 'FURNITURE' , 'NC#2', getdate()         ),
(15000003, 'Customer#15000003', '3 Second Street, Righthere, Zip 90003', 
 22, '65-125-586-3249', 1315827.30 , 'MACHINERY' , 'NC#3', getdate()       )
;

-- check source count
select count(1) from src_customer;
SQL> 853

Let’s prepare the staging table for the ETL load. This staging will become basis of subsequent merge operation. So, here we shall identify changed customer records based off of the hash column, and also newly added customer records.

-- create the staging table for ETL load
drop table if exists stg_customer;
create table stg_customer distkey(stg_custkey) as
with stg as (
    select
        custkey as stg_custkey, name as stg_name, 
        address as stg_address, nationkey as stg_nationkey, 
        phone as stg_phone, acctbal as stg_acctbal,
        mktsegment as stg_mktsegment, comment as stg_comment, 
        effective_dt as stg_effective_dt,
        FNV_HASH(address+phone) as stg_track_hash
    from
        src_customer
    )
select 
    s.* , 
    case when c.c_custkey is null then 1 else 0 end new_ind,
    case when c.c_custkey is not null 
          and s.stg_track_hash <> track_hash then 1 else 0 end track_ind
 from
    stg s
left join customer_dim c
    on s.stg_custkey = c.c_custkey
;

-- check staging count
select new_ind, track_ind, count(1) 
 from stg_customer
group by 1,2
;

NEW_IND TRACK_IND COUNT(1)
------- --------- --------
    1        0           3
    0        1         700
    0        0         150

We notice that there are 3 net new records, 700 records that have changed based on tracking fields (address and phone) and 150 records that have changes in non tracking fields. In next step we show you how to apply these changes on against 15 Million row customer dimension table.
